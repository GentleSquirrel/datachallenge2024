{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bn/74x_l6t57mncrtd65lq_drbw0000gn/T/ipykernel_30323/3221532302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#ouvre le xlsx Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Supposons que votre DataFrame s'appelle df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbtc_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BTC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'btc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset.xlsx'"
     ]
    }
   ],
   "source": [
    "#ouvre le xlsx Dataset \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#ouvre le xlsx Dataset\n",
    "df = pd.read_excel('Dataset.xlsx')\n",
    "# Supposons que votre DataFrame s'appelle df\n",
    "btc_columns = df.filter(like='BTC').columns.tolist() + df.filter(like='btc').columns.tolist()\n",
    "btc_columns = df.filter(like='ETH').columns.tolist() + df.filter(like='eth').columns.tolist()\n",
    "#sors moi un df avec les colonnes btc, en ajoutant la colonne Date\n",
    "df_btc = df[btc_columns + ['date']]\n",
    "#sur la colonne Close, fait un pct change dans une nouvelle colonne Return\n",
    "df_btc['Return_BTC'] = df_btc['Close_BTC'].pct_change()\n",
    "#drop la premiere ligne de df_btc\n",
    "df_btc = df_btc.drop(df_btc.index[0])\n",
    "# Supposons que 'value' est la colonne contenant les valeurs que vous voulez comparer\n",
    "df_btc['target'] = (df_btc['Return_BTC'].shift(-1) > df_btc['Return_BTC']).astype(int)\n",
    "# Supposons que 'date' est la colonne contenant les dates\n",
    "df_btc['date'] = pd.to_datetime(df_btc['date'])  # Assurez-vous que la colonne est de type datetime\n",
    "df_btc['year'] = df_btc['date'].dt.year\n",
    "df_btc['month'] = df_btc['date'].dt.month\n",
    "df_btc['day'] = df_btc['date'].dt.day\n",
    "df_btc['day_of_week'] = df_btc['date'].dt.dayofweek  # Lundi=0, Dimanche=6\n",
    "\n",
    "#fais un fillna 0\n",
    "df_btc = df_btc.fillna(0)\n",
    "#fais le train de 2017-08 a 2022-08 et le reste en test\n",
    "df_train = df_btc[df_btc['date'] < '2022-08-01']\n",
    "df_test = df_btc[df_btc['date'] >= '2022-08-01']\n",
    "##mets la colonne date en index \n",
    "df_train = df_train.set_index('date')\n",
    "df_test = df_test.set_index('date')\n",
    "\n",
    "X_train = df_train.drop('target',axis=1)\n",
    "y_train = df_train['target']\n",
    "X_test = df_test.drop('target',axis=1)\n",
    "y_test = df_test['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BTC</th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>btc_tweet_count</th>\n",
       "      <th>btc_posts_count</th>\n",
       "      <th>btc_textblob_polarity_min</th>\n",
       "      <th>btc_textblob_polarity_max</th>\n",
       "      <th>btc_textblob_polarity_mean</th>\n",
       "      <th>btc_vader_polarity_compound_min</th>\n",
       "      <th>btc_vader_polarity_compound_max</th>\n",
       "      <th>btc_vader_polarity_compound_mean</th>\n",
       "      <th>date</th>\n",
       "      <th>Return_BTC</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421818</td>\n",
       "      <td>0.503260</td>\n",
       "      <td>0.886973</td>\n",
       "      <td>0.605092</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>0.570604</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012854</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.065479</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.503260</td>\n",
       "      <td>0.781082</td>\n",
       "      <td>0.569420</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>0.600851</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.086423</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.503260</td>\n",
       "      <td>0.454618</td>\n",
       "      <td>0.459444</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0.646749</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.063794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503260</td>\n",
       "      <td>0.454618</td>\n",
       "      <td>0.459444</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>0.666655</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017517</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.065479</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.346339</td>\n",
       "      <td>0.454618</td>\n",
       "      <td>0.374063</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>0.716297</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close_BTC  Volume_BTC  btc_tweet_count  btc_posts_count  \\\n",
       "1   0.014290    0.000920         0.101830         0.136364   \n",
       "2   0.012854    0.000252         0.065479         0.136364   \n",
       "3   0.013227    0.000613         0.086423         0.090909   \n",
       "4   0.014377    0.000659         0.063794         0.000000   \n",
       "5   0.017517    0.000378         0.065479         0.090909   \n",
       "\n",
       "   btc_textblob_polarity_min  btc_textblob_polarity_max  \\\n",
       "1                        0.5                   0.500000   \n",
       "2                        0.5                   0.433333   \n",
       "3                        0.5                   0.400000   \n",
       "4                        0.5                   0.333333   \n",
       "5                        0.5                   0.333333   \n",
       "\n",
       "   btc_textblob_polarity_mean  btc_vader_polarity_compound_min  \\\n",
       "1                    0.421818                         0.503260   \n",
       "2                    0.366667                         0.503260   \n",
       "3                    0.366667                         0.503260   \n",
       "4                    0.333333                         0.503260   \n",
       "5                    0.333333                         0.346339   \n",
       "\n",
       "   btc_vader_polarity_compound_max  btc_vader_polarity_compound_mean  \\\n",
       "1                         0.886973                          0.605092   \n",
       "2                         0.781082                          0.569420   \n",
       "3                         0.454618                          0.459444   \n",
       "4                         0.454618                          0.459444   \n",
       "5                         0.454618                          0.374063   \n",
       "\n",
       "        date  Return_BTC  target  year  month  day  day_of_week  \n",
       "1 2017-08-18    0.570604       1  2017      8   18            4  \n",
       "2 2017-08-21    0.600851       1  2017      8   21            0  \n",
       "3 2017-08-22    0.646749       1  2017      8   22            1  \n",
       "4 2017-08-23    0.666655       1  2017      8   23            2  \n",
       "5 2017-08-24    0.716297       0  2017      8   24            3  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_btc_scaled = df_btc.copy()\n",
    "\n",
    "# Obtenir toutes les colonnes sauf la colonne de date\n",
    "columns_to_scale = df_btc.columns.drop(['date', 'target','day','month','year','day_of_week'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_btc_scaled[columns_to_scale] = scaler.fit_transform(df_btc[columns_to_scale])\n",
    "\n",
    "df_btc_scaled.head()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_btc_scaled_mm = df_btc.copy()\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "df_btc_scaled_mm[columns_to_scale] = mmscaler.fit_transform(df_btc[columns_to_scale])\n",
    "\n",
    "df_btc_scaled_mm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6941176470588235\n",
      "RMSE: 0.5530663187549721\n",
      "Close_BTC  Volume_BTC   btc_tweet_count  btc_posts_count  btc_textblob_polarity_min  btc_textblob_polarity_max  btc_textblob_polarity_mean  btc_vader_polarity_compound_min  btc_vader_polarity_compound_max  btc_vader_polarity_compound_mean  Return_BTC  year  month  day  day_of_week\n",
      "15781.29   324096.9978  898.0            1.0               0.111111                  0.111111                   0.111111                     0.0000                          0.0000                            0.000000                         -0.055038   2022  11     21   0              1\n",
      "22199.84   361958.4011  652.0            3.0               0.000000                  0.250000                   0.094444                    -0.1779                          0.0000                           -0.059300                          0.019559   2023  2      14   1              1\n",
      "21399.83   222222.0453  658.0            7.0              -0.166667                  0.144444                   0.005357                    -0.7269                          0.4404                           -0.113371                          0.027140   2022  8      22   0              1\n",
      "21529.12   200967.7716  615.0            3.0               0.187500                  0.250000                   0.229167                     0.0000                          0.4215                            0.239167                          0.006042   2022  8      23   1              1\n",
      "21559.04   169915.7830  619.0            5.0              -0.187500                  0.250000                   0.029167                    -0.2023                          0.3400                           -0.003080                          0.008937   2022  8      25   3              1\n",
      "                                                                                                                                                                                                                                                                                            ..\n",
      "19176.93   351634.3260  865.0            2.0               0.000000                  0.250000                   0.125000                    -0.3400                          0.0000                           -0.170000                         -0.010230   2022  10     14   4              1\n",
      "19227.82   439239.2194  672.0            5.0               0.066667                  0.300000                   0.191667                    -0.7506                          0.7003                           -0.160180                         -0.003219   2022  9      26   0              1\n",
      "19289.91   385886.9183  669.0            1.0               0.022222                  0.022222                   0.022222                     0.0387                          0.0387                            0.038700                         -0.005758   2022  9      23   4              1\n",
      "19292.84   287394.7788  881.0            4.0               0.100000                  0.500000                   0.283929                    -0.5859                          0.6486                           -0.168425                          0.026728   2022  9      7    2              1\n",
      "28295.41   128649.6082  786.0            5.0              -0.059524                  0.225000                   0.057095                     0.0000                          0.7725                            0.475940                          0.038327   2023  3      23   3              1\n",
      "Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, y_train, X_test):\n",
    "    \n",
    "    # Créer le modèle de forêt aléatoire\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Prédire les valeurs de l'ensemble de test\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Afficher la précision du modèle\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    #montre le RMSE \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "    #compte le nombre de 0 de df \n",
    "    print(X_test.value_counts())\n",
    "    # Retourner le modèle entraîné et les prédictions\n",
    "    return rf, y_pred\n",
    "\n",
    "# Utiliser la fonction\n",
    "rf_model, rf_pred = train_random_forest(X_train, y_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.5235294117647059\n",
      "Sensitivity (TPR) = 1.0\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.05        83\n",
      "           1       0.52      1.00      0.68        87\n",
      "\n",
      "    accuracy                           0.52       170\n",
      "   macro avg       0.76      0.51      0.36       170\n",
      "weighted avg       0.75      0.52      0.37       170\n",
      "\n",
      "RMSE: 0.6902684899626333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    logreg_acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred) # Confusion matrix\n",
    "    tpr_logreg = cm[1][1] /(cm[1][0] + cm[1][1])\n",
    "\n",
    "    print('The accuracy score is:', logreg_acc) # accuracy score\n",
    "    print('Sensitivity (TPR) =', tpr_logreg)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate the RMSE \n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "logpred = logistic_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7411764705882353\n",
      "Sensitivity (TPR) = 0.735632183908046\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74        83\n",
      "           1       0.75      0.74      0.74        87\n",
      "\n",
      "    accuracy                           0.74       170\n",
      "   macro avg       0.74      0.74      0.74       170\n",
      "weighted avg       0.74      0.74      0.74       170\n",
      "\n",
      "RMSE: 0.5087470190691683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def linear_discriminant_analysis(X_train, y_train, X_test, y_test):\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', store_covariance=True)\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # Predict Test Set Responses\n",
    "    y_predicted = lda.predict(X_test)\n",
    "    y_predicted= np.array(y_predicted > 0.5, dtype=float)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    lda_acc = accuracy_score(y_test, y_predicted)  # accuracy score\n",
    "    cm_lda = confusion_matrix(y_test, y_predicted) # Confusion matrix \n",
    "    tpr_lda = cm_lda[1][1] /(cm_lda[1][0] + cm_lda[1][1])\n",
    "\n",
    "    print('Accuracy =', lda_acc)  \n",
    "    print('Sensitivity (TPR) =', tpr_lda)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_predicted ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_predicted, squared=False))\n",
    "    return y_predicted\n",
    "\n",
    "#lance la fonction\n",
    "discri_pred = linear_discriminant_analysis(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Sensitivity (TPR) = 0.4367816091954023\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.65        83\n",
      "           1       0.67      0.44      0.53        87\n",
      "\n",
      "    accuracy                           0.60       170\n",
      "   macro avg       0.62      0.60      0.59       170\n",
      "weighted avg       0.62      0.60      0.59       170\n",
      "\n",
      "RMSE: 0.6324555320336759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "def decision_tree_classifier(X_train, y_train, X_test, y_test):\n",
    "    dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Build classification tree\n",
    "    dtree.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dtree.predict(X_test)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    dtree_acc = accuracy_score(y_test, y_pred)   # accuracy score\n",
    "    cm_dtree = confusion_matrix(y_test, y_pred) # Confusion matrix \n",
    "    tpr_dtree = cm_dtree[1][1] /(cm_dtree[1][0] + cm_dtree[1][1])\n",
    "\n",
    "    print(\"Accuracy:\",dtree_acc)\n",
    "    print('Sensitivity (TPR) =', tpr_dtree)\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_pred ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "    return y_pred\n",
    "\n",
    "decision_pred = decision_tree_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48823529411764705\n",
      "Sensitivity (TPR) = 0.0\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66        83\n",
      "           1       0.00      0.00      0.00        87\n",
      "\n",
      "    accuracy                           0.49       170\n",
      "   macro avg       0.24      0.50      0.33       170\n",
      "weighted avg       0.24      0.49      0.32       170\n",
      "\n",
      "RMSE: 0.7153773171427459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "def gradient_boosting_classifier(X_train, y_train, X_test, y_test):\n",
    "    booster = GradientBoostingClassifier(max_depth=7,n_estimators=50,min_samples_split=1400,min_samples_leaf=60,max_features=7,subsample=0.85)\n",
    "    boost_est = booster.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = boost_est.predict(X_test)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    boosting_acc = accuracy_score(y_test, y_pred) #accuracy score\n",
    "    cm_bossting = confusion_matrix(y_test, y_pred) # Confusion matrix \n",
    "    tpr_boost = cm_bossting[1][1] /(cm_bossting[1][0] + cm_bossting[1][1]) #Sensitivity (TPR)\n",
    "\n",
    "    print('Accuracy:', boosting_acc) # accuracy score\n",
    "    print('Sensitivity (TPR) =', tpr_boost)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_pred ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "    return y_pred\n",
    "\n",
    "gradient_pred = gradient_boosting_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for K = 1 nearest Neighbors:  0.5529411764705883\n",
      "RMSE: 0.6686245759238975\n",
      "Accuracy for K = 5 nearest Neighbors:  0.5\n",
      "RMSE: 0.7071067811865476\n",
      "Accuracy for K = 10 nearest Neighbors:  0.48823529411764705\n",
      "RMSE: 0.7153773171427459\n",
      "Accuracy for K = 20 nearest Neighbors:  0.5\n",
      "RMSE: 0.7071067811865476\n",
      "Accuracy for K = 30 nearest Neighbors:  0.5058823529411764\n",
      "RMSE: 0.7029350233548074\n",
      "Accuracy for K = 40 nearest Neighbors:  0.5058823529411764\n",
      "RMSE: 0.7029350233548074\n",
      "Accuracy for K = 50 nearest Neighbors:  0.4764705882352941\n",
      "RMSE: 0.7235533233734096\n"
     ]
    }
   ],
   "source": [
    "# input les données normaliser patati patata\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Creating classifiers for every value of K\n",
    "classifiers = []\n",
    "nb_neighbor = [1, 5, 10, 20, 30, 40, 50]\n",
    "for i in range(len(nb_neighbor)):\n",
    "    classifiers.append(KNeighborsClassifier(nb_neighbor[i]))\n",
    "\n",
    "# Initializing the lists for accuracy, true positive rate and true negative rate\n",
    "# Later used to compare the classifiers for different values of K\n",
    "score_list = []\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "\n",
    "# Fitting the training dataset for every classifier and calculating metrics\n",
    "\n",
    "index = 0\n",
    "for clf in classifiers: \n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    score = clf.score(X_test, y_test)  \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy for K =\", nb_neighbor[index] ,\"nearest Neighbors: \",  accuracy_score(y_test, y_pred))\n",
    "    # print le rmse\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred) # Confusion matrix  \n",
    "\n",
    "    score_list.append(score)\n",
    "    true_positive.append(cm[1][1])\n",
    "    true_negative.append(cm[0][0])\n",
    "    \n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5764705882352941\n",
      "Sensitivity (TPR) = 0.27586206896551724\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.89      0.67        83\n",
      "           1       0.73      0.28      0.40        87\n",
      "\n",
      "    accuracy                           0.58       170\n",
      "   macro avg       0.63      0.58      0.54       170\n",
      "weighted avg       0.64      0.58      0.53       170\n",
      "\n",
      "RMSE: 0.6507913734559685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def quadratic_discriminant_analysis(X_train, y_train, X_test, y_test):\n",
    "    qdaClassifier = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "    qdaClassifier.fit(X_train,y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    y_predict = qdaClassifier.predict(X_test)\n",
    "    y_predicted= np.array(y_predict > 0.5, dtype=float)\n",
    "\n",
    "    # Get evaluation criteria\n",
    "    qda_acc = accuracy_score(y_test, y_predicted) \n",
    "    qda_cm = confusion_matrix(y_test, y_predicted)\n",
    "    qda_tpr = qda_cm[1][1] /(qda_cm[1][0] + qda_cm[1][1])\n",
    "\n",
    "    print('Accuracy =', qda_acc)\n",
    "    print('Sensitivity (TPR) =', qda_tpr)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_predicted ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_predicted, squared=False))\n",
    "    return y_predicted\n",
    "\n",
    "quadratic_pred = quadratic_discriminant_analysis(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-mlogloss:0.94244\ttrain-mlogloss:0.85494\n",
      "[1]\tvalidation-mlogloss:0.85030\ttrain-mlogloss:0.70285\n",
      "[2]\tvalidation-mlogloss:0.79127\ttrain-mlogloss:0.59973\n",
      "[3]\tvalidation-mlogloss:0.75208\ttrain-mlogloss:0.52498\n",
      "[4]\tvalidation-mlogloss:0.72209\ttrain-mlogloss:0.46765\n",
      "[5]\tvalidation-mlogloss:0.69269\ttrain-mlogloss:0.42559\n",
      "[6]\tvalidation-mlogloss:0.67720\ttrain-mlogloss:0.39219\n",
      "[7]\tvalidation-mlogloss:0.66720\ttrain-mlogloss:0.36170\n",
      "[8]\tvalidation-mlogloss:0.66063\ttrain-mlogloss:0.33502\n",
      "[9]\tvalidation-mlogloss:0.65019\ttrain-mlogloss:0.31676\n",
      "[10]\tvalidation-mlogloss:0.64646\ttrain-mlogloss:0.30165\n",
      "[11]\tvalidation-mlogloss:0.64155\ttrain-mlogloss:0.29007\n",
      "[12]\tvalidation-mlogloss:0.63728\ttrain-mlogloss:0.28018\n",
      "[13]\tvalidation-mlogloss:0.64227\ttrain-mlogloss:0.26343\n",
      "[14]\tvalidation-mlogloss:0.63542\ttrain-mlogloss:0.25662\n",
      "[15]\tvalidation-mlogloss:0.63275\ttrain-mlogloss:0.24446\n",
      "[16]\tvalidation-mlogloss:0.62737\ttrain-mlogloss:0.23807\n",
      "[17]\tvalidation-mlogloss:0.62643\ttrain-mlogloss:0.22297\n",
      "[18]\tvalidation-mlogloss:0.62665\ttrain-mlogloss:0.21888\n",
      "[19]\tvalidation-mlogloss:0.62092\ttrain-mlogloss:0.20368\n",
      "[20]\tvalidation-mlogloss:0.62662\ttrain-mlogloss:0.19179\n",
      "[21]\tvalidation-mlogloss:0.62815\ttrain-mlogloss:0.18127\n",
      "[22]\tvalidation-mlogloss:0.63091\ttrain-mlogloss:0.17648\n",
      "[23]\tvalidation-mlogloss:0.62999\ttrain-mlogloss:0.17162\n",
      "[24]\tvalidation-mlogloss:0.62865\ttrain-mlogloss:0.16410\n",
      "[25]\tvalidation-mlogloss:0.62776\ttrain-mlogloss:0.15820\n",
      "[26]\tvalidation-mlogloss:0.61828\ttrain-mlogloss:0.14838\n",
      "[27]\tvalidation-mlogloss:0.62004\ttrain-mlogloss:0.14534\n",
      "[28]\tvalidation-mlogloss:0.62259\ttrain-mlogloss:0.13809\n",
      "[29]\tvalidation-mlogloss:0.62853\ttrain-mlogloss:0.13421\n",
      "[30]\tvalidation-mlogloss:0.62851\ttrain-mlogloss:0.13246\n",
      "[31]\tvalidation-mlogloss:0.62896\ttrain-mlogloss:0.13068\n",
      "[32]\tvalidation-mlogloss:0.62930\ttrain-mlogloss:0.12795\n",
      "[33]\tvalidation-mlogloss:0.63507\ttrain-mlogloss:0.12178\n",
      "[34]\tvalidation-mlogloss:0.64039\ttrain-mlogloss:0.11984\n",
      "[35]\tvalidation-mlogloss:0.64126\ttrain-mlogloss:0.11908\n",
      "[36]\tvalidation-mlogloss:0.64046\ttrain-mlogloss:0.11575\n",
      "[37]\tvalidation-mlogloss:0.64379\ttrain-mlogloss:0.11000\n",
      "[38]\tvalidation-mlogloss:0.64502\ttrain-mlogloss:0.10654\n",
      "[39]\tvalidation-mlogloss:0.64384\ttrain-mlogloss:0.10379\n",
      "[40]\tvalidation-mlogloss:0.64289\ttrain-mlogloss:0.10239\n",
      "[41]\tvalidation-mlogloss:0.64422\ttrain-mlogloss:0.09990\n",
      "[42]\tvalidation-mlogloss:0.64410\ttrain-mlogloss:0.09910\n",
      "[43]\tvalidation-mlogloss:0.64558\ttrain-mlogloss:0.09608\n",
      "[44]\tvalidation-mlogloss:0.64903\ttrain-mlogloss:0.09361\n",
      "[45]\tvalidation-mlogloss:0.65439\ttrain-mlogloss:0.08946\n",
      "[46]\tvalidation-mlogloss:0.65456\ttrain-mlogloss:0.08763\n",
      "[47]\tvalidation-mlogloss:0.65540\ttrain-mlogloss:0.08448\n",
      "[48]\tvalidation-mlogloss:0.65608\ttrain-mlogloss:0.08187\n",
      "[49]\tvalidation-mlogloss:0.65869\ttrain-mlogloss:0.08125\n",
      "RMSE of the base model: 0.564\n",
      "Accuracy of the base model: 0.682\n",
      "Confusion matrix: \n",
      " [[52 31]\n",
      " [23 64]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "def xgboost_classifier(X_train, y_train, X_test, y_test, df_test):\n",
    "    dtrain_clf = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "    dtest_clf = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "    dpred_clf = xgb.DMatrix(df_test, enable_categorical=True)\n",
    "\n",
    "    params = {\"objective\": \"multi:softmax\",\"num_class\": 3, \"tree_method\": \"hist\",\n",
    "                \"learning_rate\": 0.3, \"max_depth\": 6,\n",
    "                \"gamma\": 0, \"subsample\": 1, \"colsample_bytree\": 1,\n",
    "                \"alpha\": 0, \"lambda\": 1,\"random_state\": 0}\n",
    "\n",
    "    n = 50\n",
    "    evals = [(dtest_clf, \"validation\"), (dtrain_clf, \"train\")]\n",
    "\n",
    "    model = xgb.train(\n",
    "       params=params,\n",
    "       dtrain=dtrain_clf,\n",
    "       num_boost_round=n,\n",
    "       evals=evals,\n",
    "       verbose_eval=1,\n",
    "       # Activate early stopping\n",
    "       early_stopping_rounds=30\n",
    "    )\n",
    "    preds = model.predict(dtest_clf)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    accuracy = accuracy_score(y_test, preds.round())\n",
    "\n",
    "    print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "    print(f\"Accuracy of the base model: {accuracy:.3f}\") \n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, preds)\n",
    "    print(\"Confusion matrix: \\n\", conf_matrix)\n",
    "    return preds\n",
    "\n",
    "xgb_pred = xgboost_classifier(X_train, y_train, X_test, y_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supposons que preds_dtree, preds_boost, preds_qda et preds_xgb sont vos prédictions\n",
    "df_preds = pd.DataFrame({\n",
    "    'RF': rf_pred,\n",
    "    'logreg': logpred,\n",
    "    'discri': discri_pred,\n",
    "    'dtree': decision_pred,\n",
    "    'boost': gradient_pred,\n",
    "    'qda': quadratic_pred,\n",
    "    'xgb': xgb_pred\n",
    "}, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "import time\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "# MLA = [\n",
    "#         #Ensemble Methods\n",
    "#         ensemble.AdaBoostClassifier(),\n",
    "#         ensemble.BaggingClassifier(),\n",
    "#         ensemble.ExtraTreesClassifier(),\n",
    "#         ensemble.GradientBoostingClassifier(),\n",
    "#         ensemble.RandomForestClassifier(),\n",
    "\n",
    "#         #Gaussian Processes\n",
    "#         gaussian_process.GaussianProcessClassifier(),\n",
    "        \n",
    "#         #GLM\n",
    "#         linear_model.LogisticRegressionCV(),\n",
    "#         linear_model.PassiveAggressiveClassifier(),\n",
    "#         linear_model.RidgeClassifierCV(),\n",
    "#         linear_model.SGDClassifier(),\n",
    "#         linear_model.Perceptron(),\n",
    "        \n",
    "#         #Navies Bayes\n",
    "#         naive_bayes.BernoulliNB(),\n",
    "#         naive_bayes.GaussianNB(),\n",
    "        \n",
    "#         #Nearest Neighbor\n",
    "#         neighbors.KNeighborsClassifier(),\n",
    "        \n",
    "#         #SVM\n",
    "#         svm.SVC(probability=True),\n",
    "        \n",
    "#         #Trees    \n",
    "#         tree.DecisionTreeClassifier(),\n",
    "#         tree.ExtraTreeClassifier(),\n",
    "        \n",
    "#         #Discriminant Analysis\n",
    "#         discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "#         discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "#         #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "#         XGBClassifier()    \n",
    "#         ]\n",
    "\n",
    "\n",
    "\n",
    "# #split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "# #note: this is an alternative to train_test_split\n",
    "# #cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "# #create table to compare MLA metrics\n",
    "# MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean','MLA Time','MLA RMSE']\n",
    "# MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# #create table to compare MLA predictions\n",
    "# MLA_predict = y_train.copy()\n",
    "\n",
    "# #index through MLA and save performance to table\n",
    "# row_index = 0\n",
    "# for alg in MLA:\n",
    "\n",
    "#     #set name and parameters\n",
    "#     MLA_name = alg.__class__.__name__\n",
    "#     MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "#     MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "#     # #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "#     # cv_results = model_selection.cross_validate(alg, X_train, y_train, cv  = cv_split)\n",
    "\n",
    "#     # #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "#     # MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "#     #save MLA predictions - see section 6 for usag\n",
    "#     start_time = time.time()\n",
    "#     alg.fit(X_train, y_train)\n",
    "#     predictions = alg.predict(X_test)\n",
    "#     end_time = time.time()\n",
    "#     # Calculer le RMSE et l'ajouter à la table\n",
    "#     accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "#     # Save the metrics to the table\n",
    "#     MLA_compare.loc[row_index, 'MLA Time'] = end_time - start_time\n",
    "#     MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = accuracy\n",
    "#     MLA_compare.loc[row_index, 'MLA RMSE'] = rmse\n",
    "    \n",
    "    \n",
    "#     MLA_predict[MLA_name] = predictions\n",
    "    \n",
    "#     row_index+=1\n",
    "\n",
    "    \n",
    "# #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "# MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "# MLA_compare1 = MLA_compare.copy()\n",
    "# MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml_models(X_train, y_train, X_test, y_test,df):\n",
    "    from sklearn import ensemble, gaussian_process, linear_model, naive_bayes, neighbors, svm, tree, discriminant_analysis\n",
    "    from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    seed = 42  # Vous pouvez choisir n'importe quel nombre pour la graine\n",
    "\n",
    "    MLA = [\n",
    "        ensemble.AdaBoostClassifier(random_state=seed),\n",
    "        ensemble.BaggingClassifier(random_state=seed),\n",
    "        ensemble.ExtraTreesClassifier(random_state=seed),\n",
    "        ensemble.GradientBoostingClassifier(random_state=seed),\n",
    "        ensemble.RandomForestClassifier(random_state=seed),\n",
    "        gaussian_process.GaussianProcessClassifier(random_state=seed),\n",
    "        linear_model.LogisticRegressionCV(random_state=seed),\n",
    "        linear_model.PassiveAggressiveClassifier(random_state=seed),\n",
    "        linear_model.RidgeClassifierCV(),  # Pas de random_state pour RidgeClassifierCV\n",
    "        linear_model.SGDClassifier(random_state=seed),\n",
    "        linear_model.Perceptron(random_state=seed),\n",
    "        naive_bayes.BernoulliNB(),\n",
    "        naive_bayes.GaussianNB(),\n",
    "        neighbors.KNeighborsClassifier(),\n",
    "        svm.SVC(probability=True, random_state=seed),\n",
    "        tree.DecisionTreeClassifier(random_state=seed),\n",
    "        tree.ExtraTreeClassifier(random_state=seed),\n",
    "        discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "        XGBClassifier(random_state=seed)    \n",
    "    ]\n",
    "\n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean','MLA Time','MLA RMSE']\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "    MLA_predict = y_train.copy()\n",
    "\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "        start_time = time.time()\n",
    "        alg.fit(X_train, y_train)\n",
    "        predictions = alg.predict(X_test)\n",
    "        alg.fit(df.drop('target', axis=1), df['target'])\n",
    "        last_date_prediction = alg.predict(df.drop('target', axis=1).iloc[-1:])\n",
    "        end_time = time.time()\n",
    "\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "        MLA_compare.loc[row_index, 'MLA Time'] = end_time - start_time\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = accuracy\n",
    "        MLA_compare.loc[row_index, 'MLA RMSE'] = rmse\n",
    "\n",
    "        MLA_predict[MLA_name] = last_date_prediction\n",
    "\n",
    "        row_index+=1\n",
    "\n",
    "    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "    return MLA_compare, MLA_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLA_compare, MLA_predict = run_ml_models(X_train, y_train, X_test, y_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 00:00:00 2022-08-01 00:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bn/74x_l6t57mncrtd65lq_drbw0000gn/T/ipykernel_30323/1239549914.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Prédire la valeur pour le jour suivant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mnext_day_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_month\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_month\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_month\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Ajouter la prédiction, le nom du modèle, l'accuracy et le RMSE au DataFrame des prédictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bn/74x_l6t57mncrtd65lq_drbw0000gn/T/ipykernel_30323/1239549914.py\u001b[0m in \u001b[0;36mpredict_next_day\u001b[0;34m(X_train, y_train, X_test, y_test, df, current_month, previous_month, best_model)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Si nous sommes dans un nouveau mois ou si aucun meilleur modèle n'a encore été trouvé\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_model_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprevious_month\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcurrent_month\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mMLA_compare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLA_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ml_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Calculer le ratio Accuracy/RMSE pour chaque modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bn/74x_l6t57mncrtd65lq_drbw0000gn/T/ipykernel_30323/1003334174.py\u001b[0m in \u001b[0;36mrun_ml_models\u001b[0;34m(X_train, y_train, X_test, y_test, df)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mlast_date_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \"\"\"\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    872\u001b[0m         ]\n\u001b[1;32m    873\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n\u001b[0m\u001b[1;32m    875\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \"\"\"\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Supposons que df_full est votre DataFrame complet qui contient toutes les données\n",
    "\n",
    "# Fonction pour créer un DataFrame pour une période donnée\n",
    "def create_df(start_date, end_date):\n",
    "    # Pour cet exemple, nous allons simplement filtrer df_full pour obtenir les données dans la période spécifiée.\n",
    "    df = df_btc[(df_btc['date'] >= start_date) & (df_btc['date'] <= end_date)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def predict_next_day(X_train, y_train, X_test, y_test, df, current_month, previous_month, best_model):\n",
    "    # Si nous sommes dans un nouveau mois ou si aucun meilleur modèle n'a encore été trouvé\n",
    "    if best_model_name is None or previous_month != current_month:\n",
    "        MLA_compare, MLA_predict = run_ml_models(X_train, y_train, X_test, y_test, df)\n",
    "        \n",
    "        # Calculer le ratio Accuracy/RMSE pour chaque modèle\n",
    "        MLA_compare['Accuracy/RMSE'] = MLA_compare['MLA Test Accuracy Mean'] / MLA_compare['MLA RMSE']\n",
    "        \n",
    "        # Trouver le modèle avec le meilleur ratio Accuracy/RMSE\n",
    "        MLA_compare['Accuracy/RMSE'] = pd.to_numeric(MLA_compare['Accuracy/RMSE'], errors='coerce')\n",
    "        best_model = MLA_compare.loc[MLA_compare['Accuracy/RMSE'].idxmax()]\n",
    "        print(best_model['MLA Name'])\n",
    "        previous_month = current_month\n",
    "    else :\n",
    "        previous_month = current_month\n",
    "        MLA_compare, MLA_predict = run_ml_models(X_train, y_train, X_test, y_test, df)\n",
    "        best_model = best_model\n",
    "        print(best_model['MLA Name'])\n",
    "        previous_month = current_month\n",
    "\n",
    "    \n",
    "    \n",
    "    return MLA_predict[best_model['MLA Name']], best_model['MLA Name'], best_model['MLA Test Accuracy Mean'], best_model['MLA RMSE'], previous_month, best_model\n",
    "\n",
    "\n",
    "# Initialiser la date de début et la date de fin\n",
    "prediction_start_date = datetime(2022, 8, 1)\n",
    "#end_date = df_btc['date'].max()\n",
    "end_date = datetime(2022,10,1)\n",
    "\n",
    "\n",
    "#isole un df qui contient les données entre les deux dates \n",
    "df = create_df(prediction_start_date, end_date)\n",
    "\n",
    "#récupère toute la colonne date afin de boucler dessus donc dans un nouveau df \n",
    "df_date = df['date']\n",
    "\n",
    "#mets df_date dans un dataframe\n",
    "df_date = pd.DataFrame(df_date)\n",
    "\n",
    "# Initialiser une liste vide pour stocker les dates de début\n",
    "start_dates = []\n",
    "\n",
    "# Parcourir chaque date dans df_date\n",
    "for date in df_date['date']:\n",
    "    # Calculer la date de début comme étant six mois avant la date actuelle\n",
    "    start_date = date - pd.DateOffset(months=6)\n",
    "    \n",
    "    # Vérifier si start_date est dans df_btc['date']\n",
    "    if start_date not in df_btc['date'].values:\n",
    "        # Si start_date n'est pas dans df_btc['date'], trouver la date la plus proche qui est dans df_btc['date']\n",
    "        start_date = df_btc['date'][df_btc['date'].sub(start_date).abs().idxmin()]\n",
    "    \n",
    "    # Ajouter la date de début à la liste start_dates\n",
    "    start_dates.append(start_date)\n",
    "\n",
    "# Ajouter la liste start_dates comme une nouvelle colonne 'start_date' dans df\n",
    "df_date['start_date'] = start_dates\n",
    "# Initialiser le DataFrame pour stocker les prédictions\n",
    "predictions_df = pd.DataFrame(columns=['date', 'prediction'])\n",
    "\n",
    "# Initialiser le meilleur modèle\n",
    "best_model_name = None\n",
    "best_model_accuracy = None\n",
    "best_model_rmse = None\n",
    "current_month = None\n",
    "previous_month = None\n",
    "best_model = None\n",
    "\n",
    "# Boucle sur chaque ligne dans df_Date\n",
    "for index, row in df_date.iterrows():\n",
    "    # Utiliser la valeur de la colonne 'date' comme current_date\n",
    "    current_date = row['date']\n",
    "    # Utiliser la valeur de la colonne 'start_date' comme window_start_date\n",
    "    window_start_date = row['start_date']\n",
    "\n",
    "    # Créer le DataFrame pour la période de la fenêtre glissante\n",
    "    df = create_df(window_start_date, current_date)\n",
    "    print(df['date'].min(), df['date'].max())\n",
    "\n",
    "    # Supposons que df est votre DataFrame\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(len(df) * train_ratio)\n",
    "\n",
    "    df_train = df.iloc[:train_size]\n",
    "    df_test = df.iloc[train_size:]\n",
    "\n",
    "    df_train = df_train.set_index('date')\n",
    "    df_test = df_test.set_index('date')\n",
    "\n",
    "    X_train = df_train.drop('target',axis=1)\n",
    "    y_train = df_train['target']\n",
    "    X_test = df_test.drop('target',axis=1)\n",
    "    y_test = df_test['target']\n",
    "\n",
    "    current_month = df['month'].iloc[-1]\n",
    "\n",
    "    #drop la colonne date\n",
    "    df = df.drop('date', axis=1)\n",
    "    \n",
    "    # Prédire la valeur pour le jour suivant\n",
    "    next_day_prediction, best_model_name, best_model_accuracy, best_model_rmse, previous_month, best_model = predict_next_day(X_train, y_train, X_test, y_test, df, current_month, previous_month, best_model)\n",
    "    \n",
    "    # Ajouter la prédiction, le nom du modèle, l'accuracy et le RMSE au DataFrame des prédictions\n",
    "    predictions_df = predictions_df.append({\n",
    "        'date': current_date, \n",
    "        'prediction': next_day_prediction,\n",
    "        'model': best_model_name,\n",
    "        'accuracy': best_model_accuracy,\n",
    "        'RMSE': best_model_rmse\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de prédictions correctes : 154\n"
     ]
    }
   ],
   "source": [
    "# Fusionner predictions_df et df_btc sur la colonne 'date'\n",
    "df_merged = pd.merge(predictions_df, df_btc[['date', 'target']], on='date')\n",
    "\n",
    "# Comparer les colonnes 'prediction' et 'target'\n",
    "df_merged['correct'] = df_merged['prediction'] == df_merged['target']\n",
    "\n",
    "# Compter le nombre de prédictions correctes\n",
    "num_correct_predictions = df_merged['correct'].sum()\n",
    "\n",
    "print(f\"Nombre de prédictions correctes : {num_correct_predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
