{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/74x_l6t57mncrtd65lq_drbw0000gn/T/ipykernel_30323/898354688.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_btc['Return_BTC'] = df_btc['Close_ETH'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "#ouvre le xlsx Dataset \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#ouvre le xlsx Dataset\n",
    "df = pd.read_excel('Dataset.xlsx')\n",
    "# Supposons que votre DataFrame s'appelle df\n",
    "btc_columns = df.filter(like='BTC').columns.tolist() + df.filter(like='btc').columns.tolist()\n",
    "btc_columns = df.filter(like='ETH').columns.tolist() + df.filter(like='eth').columns.tolist()\n",
    "#sors moi un df avec les colonnes btc, en ajoutant la colonne Date\n",
    "df_btc = df[btc_columns + ['date']]\n",
    "#sur la colonne Close, fait un pct change dans une nouvelle colonne Return\n",
    "df_btc['Return_BTC'] = df_btc['Close_ETH'].pct_change()\n",
    "#drop la premiere ligne de df_btc\n",
    "df_btc = df_btc.drop(df_btc.index[0])\n",
    "# Supposons que 'value' est la colonne contenant les valeurs que vous voulez comparer\n",
    "df_btc['target'] = (df_btc['Return_BTC'].shift(-1) > df_btc['Return_BTC']).astype(int)\n",
    "# Supposons que 'date' est la colonne contenant les dates\n",
    "df_btc['date'] = pd.to_datetime(df_btc['date'])  # Assurez-vous que la colonne est de type datetime\n",
    "df_btc['year'] = df_btc['date'].dt.year\n",
    "df_btc['month'] = df_btc['date'].dt.month\n",
    "df_btc['day'] = df_btc['date'].dt.day\n",
    "df_btc['day_of_week'] = df_btc['date'].dt.dayofweek  # Lundi=0, Dimanche=6\n",
    "\n",
    "#fais un fillna 0\n",
    "df_btc = df_btc.fillna(0)\n",
    "#fais le train de 2017-08 a 2022-08 et le reste en test\n",
    "df_train = df_btc[df_btc['date'] < '2022-08-01']\n",
    "df_test = df_btc[df_btc['date'] >= '2022-08-01']\n",
    "##mets la colonne date en index \n",
    "df_train = df_train.set_index('date')\n",
    "df_test = df_test.set_index('date')\n",
    "\n",
    "X_train = df_train.drop('target',axis=1)\n",
    "y_train = df_train['target']\n",
    "X_test = df_test.drop('target',axis=1)\n",
    "y_test = df_test['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_ETH</th>\n",
       "      <th>Volume_ETH</th>\n",
       "      <th>eth_tweet_count</th>\n",
       "      <th>eth_posts_count</th>\n",
       "      <th>eth_textblob_polarity_min</th>\n",
       "      <th>eth_textblob_polarity_max</th>\n",
       "      <th>eth_textblob_polarity_mean</th>\n",
       "      <th>eth_vader_polarity_compound_min</th>\n",
       "      <th>eth_vader_polarity_compound_max</th>\n",
       "      <th>eth_vader_polarity_compound_mean</th>\n",
       "      <th>date</th>\n",
       "      <th>Return_BTC</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044482</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.835544</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.299749</td>\n",
       "      <td>0.974778</td>\n",
       "      <td>0.621018</td>\n",
       "      <td>0.271410</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>0.479407</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050690</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.464191</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.196069</td>\n",
       "      <td>0.363965</td>\n",
       "      <td>0.841715</td>\n",
       "      <td>0.277640</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>0.623908</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.657604</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.066698</td>\n",
       "      <td>0.444618</td>\n",
       "      <td>0.600481</td>\n",
       "      <td>0.316604</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0.462139</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049092</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.851017</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.319808</td>\n",
       "      <td>0.491935</td>\n",
       "      <td>0.867361</td>\n",
       "      <td>0.442096</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>0.531762</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.050718</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.696286</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.206135</td>\n",
       "      <td>0.415681</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.386197</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>0.537650</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close_ETH  Volume_ETH  eth_tweet_count  eth_posts_count  \\\n",
       "1   0.044482    0.001818         0.004474         0.682927   \n",
       "2   0.050690    0.000892         0.006067         0.512195   \n",
       "3   0.047835    0.001479         0.007811         0.707317   \n",
       "4   0.049092    0.001631         0.005081         0.512195   \n",
       "5   0.050718    0.001221         0.004702         0.707317   \n",
       "\n",
       "   eth_textblob_polarity_min  eth_textblob_polarity_max  \\\n",
       "1                   0.835544                       0.50   \n",
       "2                   0.464191                       0.50   \n",
       "3                   0.657604                       0.25   \n",
       "4                   0.851017                       0.70   \n",
       "5                   0.696286                       0.60   \n",
       "\n",
       "   eth_textblob_polarity_mean  eth_vader_polarity_compound_min  \\\n",
       "1                    0.299749                         0.974778   \n",
       "2                    0.196069                         0.363965   \n",
       "3                    0.066698                         0.444618   \n",
       "4                    0.319808                         0.491935   \n",
       "5                    0.206135                         0.415681   \n",
       "\n",
       "   eth_vader_polarity_compound_max  eth_vader_polarity_compound_mean  \\\n",
       "1                         0.621018                          0.271410   \n",
       "2                         0.841715                          0.277640   \n",
       "3                         0.600481                          0.316604   \n",
       "4                         0.867361                          0.442096   \n",
       "5                         0.613504                          0.386197   \n",
       "\n",
       "        date  Return_BTC  target  year  month  day  day_of_week  \n",
       "1 2017-08-18    0.479407       1  2017      8   18            4  \n",
       "2 2017-08-21    0.623908       0  2017      8   21            0  \n",
       "3 2017-08-22    0.462139       1  2017      8   22            1  \n",
       "4 2017-08-23    0.531762       1  2017      8   23            2  \n",
       "5 2017-08-24    0.537650       0  2017      8   24            3  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_btc_scaled = df_btc.copy()\n",
    "\n",
    "# Obtenir toutes les colonnes sauf la colonne de date\n",
    "columns_to_scale = df_btc.columns.drop(['date', 'target','day','month','year','day_of_week'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_btc_scaled[columns_to_scale] = scaler.fit_transform(df_btc[columns_to_scale])\n",
    "\n",
    "df_btc_scaled.head()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_btc_scaled_mm = df_btc.copy()\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "df_btc_scaled_mm[columns_to_scale] = mmscaler.fit_transform(df_btc[columns_to_scale])\n",
    "\n",
    "df_btc_scaled_mm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6529411764705882\n",
      "RMSE: 0.5891169862849074\n",
      "Close_ETH  Volume_ETH    eth_tweet_count  eth_posts_count  eth_textblob_polarity_min  eth_textblob_polarity_max  eth_textblob_polarity_mean  eth_vader_polarity_compound_min  eth_vader_polarity_compound_max  eth_vader_polarity_compound_mean  Return_BTC  year  month  day  day_of_week\n",
      "1102.73    2.494798e+06  575.0            30.0             -0.221212                  0.600000                   0.113642                    -0.8442                          0.8807                           0.033787                          -0.173843   2022  11     9    2              1\n",
      "1609.01    1.419827e+06  548.0            29.0             -0.400000                  0.700000                   0.116384                    -0.6258                          0.9744                           0.262541                          -0.128564   2022  8      19   4              1\n",
      "1578.48    5.275393e+05  526.0            0.0               0.000000                  0.000000                   0.000000                     0.0000                          0.0000                           0.000000                           0.003682   2022  11     1    1              1\n",
      "1585.33    3.488567e+05  501.0            29.0             -0.200000                  0.497381                   0.141770                    -0.7096                          0.9719                           0.260714                           0.012214   2023  1      31   1              1\n",
      "1586.16    7.287105e+05  540.0            19.0              0.000000                  0.500000                   0.188368                    -0.8442                          0.8977                           0.115111                           0.020629   2022  9      1    3              1\n",
      "                                                                                                                                                                                                                                                                                             ..\n",
      "1328.02    8.605849e+05  490.0            24.0             -0.300000                  0.750000                   0.154556                    -0.8442                          0.9865                           0.274208                          -0.006100   2022  9      27   1              1\n",
      "1328.72    7.407536e+05  508.0            27.0             -0.208333                  0.750000                   0.169822                    -0.8689                          0.8953                           0.277419                          -0.005226   2022  9      30   4              1\n",
      "1331.10    4.919999e+05  471.0            31.0             -0.800000                  0.600000                   0.069836                    -0.8555                          0.9353                           0.184348                          -0.015502   2022  10     7    4              1\n",
      "1331.40    4.598485e+05  1194.0           0.0               0.000000                  0.000000                   0.000000                     0.0000                          0.0000                           0.000000                           0.027101   2022  10     17   0              1\n",
      "1958.28    7.176281e+05  617.0            0.0               0.000000                  0.000000                   0.000000                     0.0000                          0.0000                           0.000000                           0.041533   2022  8      12   4              1\n",
      "Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, y_train, X_test):\n",
    "    \n",
    "    # Créer le modèle de forêt aléatoire\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Prédire les valeurs de l'ensemble de test\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Afficher la précision du modèle\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    #montre le RMSE \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "    #compte le nombre de 0 de df \n",
    "    print(X_test.value_counts())\n",
    "    # Retourner le modèle entraîné et les prédictions\n",
    "    return rf, y_pred\n",
    "\n",
    "# Utiliser la fonction\n",
    "rf_model, rf_pred = train_random_forest(X_train, y_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.5411764705882353\n",
      "Sensitivity (TPR) = 0.6705882352941176\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.47        85\n",
      "           1       0.53      0.67      0.59        85\n",
      "\n",
      "    accuracy                           0.54       170\n",
      "   macro avg       0.54      0.54      0.53       170\n",
      "weighted avg       0.54      0.54      0.53       170\n",
      "\n",
      "RMSE: 0.6773651374345779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    logreg_acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred) # Confusion matrix\n",
    "    tpr_logreg = cm[1][1] /(cm[1][0] + cm[1][1])\n",
    "\n",
    "    print('The accuracy score is:', logreg_acc) # accuracy score\n",
    "    print('Sensitivity (TPR) =', tpr_logreg)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate the RMSE \n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "logpred = logistic_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.711764705882353\n",
      "Sensitivity (TPR) = 0.6235294117647059\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74        85\n",
      "           1       0.76      0.62      0.68        85\n",
      "\n",
      "    accuracy                           0.71       170\n",
      "   macro avg       0.72      0.71      0.71       170\n",
      "weighted avg       0.72      0.71      0.71       170\n",
      "\n",
      "RMSE: 0.5368754921931593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def linear_discriminant_analysis(X_train, y_train, X_test, y_test):\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', store_covariance=True)\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # Predict Test Set Responses\n",
    "    y_predicted = lda.predict(X_test)\n",
    "    y_predicted= np.array(y_predicted > 0.5, dtype=float)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    lda_acc = accuracy_score(y_test, y_predicted)  # accuracy score\n",
    "    cm_lda = confusion_matrix(y_test, y_predicted) # Confusion matrix \n",
    "    tpr_lda = cm_lda[1][1] /(cm_lda[1][0] + cm_lda[1][1])\n",
    "\n",
    "    print('Accuracy =', lda_acc)  \n",
    "    print('Sensitivity (TPR) =', tpr_lda)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_predicted ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_predicted, squared=False))\n",
    "    return y_predicted\n",
    "\n",
    "#lance la fonction\n",
    "discri_pred = linear_discriminant_analysis(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6235294117647059\n",
      "Sensitivity (TPR) = 0.611764705882353\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        85\n",
      "           1       0.63      0.61      0.62        85\n",
      "\n",
      "    accuracy                           0.62       170\n",
      "   macro avg       0.62      0.62      0.62       170\n",
      "weighted avg       0.62      0.62      0.62       170\n",
      "\n",
      "RMSE: 0.6135719910778964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "def decision_tree_classifier(X_train, y_train, X_test, y_test):\n",
    "    dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Build classification tree\n",
    "    dtree.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dtree.predict(X_test)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    dtree_acc = accuracy_score(y_test, y_pred)   # accuracy score\n",
    "    cm_dtree = confusion_matrix(y_test, y_pred) # Confusion matrix \n",
    "    tpr_dtree = cm_dtree[1][1] /(cm_dtree[1][0] + cm_dtree[1][1])\n",
    "\n",
    "    print(\"Accuracy:\",dtree_acc)\n",
    "    print('Sensitivity (TPR) =', tpr_dtree)\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_pred ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "    return y_pred\n",
    "\n",
    "decision_pred = decision_tree_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Sensitivity (TPR) = 0.0\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        85\n",
      "           1       0.00      0.00      0.00        85\n",
      "\n",
      "    accuracy                           0.50       170\n",
      "   macro avg       0.25      0.50      0.33       170\n",
      "weighted avg       0.25      0.50      0.33       170\n",
      "\n",
      "RMSE: 0.7071067811865476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "def gradient_boosting_classifier(X_train, y_train, X_test, y_test):\n",
    "    booster = GradientBoostingClassifier(max_depth=7,n_estimators=50,min_samples_split=1400,min_samples_leaf=60,max_features=7,subsample=0.85)\n",
    "    boost_est = booster.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = boost_est.predict(X_test)\n",
    "\n",
    "    # Evaluation: Confusion matrix\n",
    "    boosting_acc = accuracy_score(y_test, y_pred) #accuracy score\n",
    "    cm_bossting = confusion_matrix(y_test, y_pred) # Confusion matrix \n",
    "    tpr_boost = cm_bossting[1][1] /(cm_bossting[1][0] + cm_bossting[1][1]) #Sensitivity (TPR)\n",
    "\n",
    "    print('Accuracy:', boosting_acc) # accuracy score\n",
    "    print('Sensitivity (TPR) =', tpr_boost)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_pred ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "    return y_pred\n",
    "\n",
    "gradient_pred = gradient_boosting_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for K = 1 nearest Neighbors:  0.4294117647058823\n",
      "RMSE: 0.7553729114113886\n",
      "Accuracy for K = 5 nearest Neighbors:  0.47058823529411764\n",
      "RMSE: 0.7276068751089989\n",
      "Accuracy for K = 10 nearest Neighbors:  0.5352941176470588\n",
      "RMSE: 0.6816933932149711\n",
      "Accuracy for K = 20 nearest Neighbors:  0.5764705882352941\n",
      "RMSE: 0.6507913734559685\n",
      "Accuracy for K = 30 nearest Neighbors:  0.5823529411764706\n",
      "RMSE: 0.6462561866810479\n",
      "Accuracy for K = 40 nearest Neighbors:  0.5588235294117647\n",
      "RMSE: 0.6642111641550714\n",
      "Accuracy for K = 50 nearest Neighbors:  0.5\n",
      "RMSE: 0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "# input les données normaliser patati patata\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Creating classifiers for every value of K\n",
    "classifiers = []\n",
    "nb_neighbor = [1, 5, 10, 20, 30, 40, 50]\n",
    "for i in range(len(nb_neighbor)):\n",
    "    classifiers.append(KNeighborsClassifier(nb_neighbor[i]))\n",
    "\n",
    "# Initializing the lists for accuracy, true positive rate and true negative rate\n",
    "# Later used to compare the classifiers for different values of K\n",
    "score_list = []\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "\n",
    "# Fitting the training dataset for every classifier and calculating metrics\n",
    "\n",
    "index = 0\n",
    "for clf in classifiers: \n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    score = clf.score(X_test, y_test)  \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy for K =\", nb_neighbor[index] ,\"nearest Neighbors: \",  accuracy_score(y_test, y_pred))\n",
    "    # print le rmse\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred) # Confusion matrix  \n",
    "\n",
    "    score_list.append(score)\n",
    "    true_positive.append(cm[1][1])\n",
    "    true_negative.append(cm[0][0])\n",
    "    \n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5352941176470588\n",
      "Sensitivity (TPR) = 0.6823529411764706\n",
      "\n",
      " Confusion matrix \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.39      0.46        85\n",
      "           1       0.53      0.68      0.59        85\n",
      "\n",
      "    accuracy                           0.54       170\n",
      "   macro avg       0.54      0.54      0.53       170\n",
      "weighted avg       0.54      0.54      0.53       170\n",
      "\n",
      "RMSE: 0.6816933932149711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def quadratic_discriminant_analysis(X_train, y_train, X_test, y_test):\n",
    "    qdaClassifier = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "    qdaClassifier.fit(X_train,y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    y_predict = qdaClassifier.predict(X_test)\n",
    "    y_predicted= np.array(y_predict > 0.5, dtype=float)\n",
    "\n",
    "    # Get evaluation criteria\n",
    "    qda_acc = accuracy_score(y_test, y_predicted) \n",
    "    qda_cm = confusion_matrix(y_test, y_predicted)\n",
    "    qda_tpr = qda_cm[1][1] /(qda_cm[1][0] + qda_cm[1][1])\n",
    "\n",
    "    print('Accuracy =', qda_acc)\n",
    "    print('Sensitivity (TPR) =', qda_tpr)\n",
    "\n",
    "    print('\\n Confusion matrix \\n \\n')\n",
    "    print(classification_report(y_test, y_predicted ))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    print('RMSE:', mean_squared_error(y_test, y_predicted, squared=False))\n",
    "    return y_predicted\n",
    "\n",
    "quadratic_pred = quadratic_discriminant_analysis(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-mlogloss:0.93839\ttrain-mlogloss:0.85431\n",
      "[1]\tvalidation-mlogloss:0.83887\ttrain-mlogloss:0.69566\n",
      "[2]\tvalidation-mlogloss:0.78052\ttrain-mlogloss:0.58871\n",
      "[3]\tvalidation-mlogloss:0.73040\ttrain-mlogloss:0.51224\n",
      "[4]\tvalidation-mlogloss:0.69677\ttrain-mlogloss:0.44926\n",
      "[5]\tvalidation-mlogloss:0.67627\ttrain-mlogloss:0.40370\n",
      "[6]\tvalidation-mlogloss:0.65769\ttrain-mlogloss:0.36569\n",
      "[7]\tvalidation-mlogloss:0.64938\ttrain-mlogloss:0.33827\n",
      "[8]\tvalidation-mlogloss:0.63924\ttrain-mlogloss:0.31477\n",
      "[9]\tvalidation-mlogloss:0.62754\ttrain-mlogloss:0.28965\n",
      "[10]\tvalidation-mlogloss:0.63422\ttrain-mlogloss:0.27107\n",
      "[11]\tvalidation-mlogloss:0.63185\ttrain-mlogloss:0.25724\n",
      "[12]\tvalidation-mlogloss:0.62668\ttrain-mlogloss:0.24480\n",
      "[13]\tvalidation-mlogloss:0.62338\ttrain-mlogloss:0.23053\n",
      "[14]\tvalidation-mlogloss:0.62281\ttrain-mlogloss:0.21843\n",
      "[15]\tvalidation-mlogloss:0.61891\ttrain-mlogloss:0.20838\n",
      "[16]\tvalidation-mlogloss:0.62092\ttrain-mlogloss:0.20037\n",
      "[17]\tvalidation-mlogloss:0.63566\ttrain-mlogloss:0.19075\n",
      "[18]\tvalidation-mlogloss:0.63081\ttrain-mlogloss:0.17779\n",
      "[19]\tvalidation-mlogloss:0.62446\ttrain-mlogloss:0.16714\n",
      "[20]\tvalidation-mlogloss:0.62519\ttrain-mlogloss:0.16124\n",
      "[21]\tvalidation-mlogloss:0.62926\ttrain-mlogloss:0.15616\n",
      "[22]\tvalidation-mlogloss:0.62988\ttrain-mlogloss:0.15168\n",
      "[23]\tvalidation-mlogloss:0.62968\ttrain-mlogloss:0.14613\n",
      "[24]\tvalidation-mlogloss:0.63324\ttrain-mlogloss:0.13680\n",
      "[25]\tvalidation-mlogloss:0.63313\ttrain-mlogloss:0.13239\n",
      "[26]\tvalidation-mlogloss:0.64262\ttrain-mlogloss:0.12827\n",
      "[27]\tvalidation-mlogloss:0.65152\ttrain-mlogloss:0.12419\n",
      "[28]\tvalidation-mlogloss:0.65067\ttrain-mlogloss:0.11864\n",
      "[29]\tvalidation-mlogloss:0.64548\ttrain-mlogloss:0.11215\n",
      "[30]\tvalidation-mlogloss:0.64602\ttrain-mlogloss:0.10735\n",
      "[31]\tvalidation-mlogloss:0.64422\ttrain-mlogloss:0.10240\n",
      "[32]\tvalidation-mlogloss:0.64600\ttrain-mlogloss:0.10045\n",
      "[33]\tvalidation-mlogloss:0.64705\ttrain-mlogloss:0.09511\n",
      "[34]\tvalidation-mlogloss:0.64865\ttrain-mlogloss:0.09207\n",
      "[35]\tvalidation-mlogloss:0.64700\ttrain-mlogloss:0.08958\n",
      "[36]\tvalidation-mlogloss:0.65259\ttrain-mlogloss:0.08445\n",
      "[37]\tvalidation-mlogloss:0.66639\ttrain-mlogloss:0.08089\n",
      "[38]\tvalidation-mlogloss:0.67469\ttrain-mlogloss:0.07794\n",
      "[39]\tvalidation-mlogloss:0.67902\ttrain-mlogloss:0.07426\n",
      "[40]\tvalidation-mlogloss:0.69055\ttrain-mlogloss:0.07218\n",
      "[41]\tvalidation-mlogloss:0.69284\ttrain-mlogloss:0.07086\n",
      "[42]\tvalidation-mlogloss:0.69516\ttrain-mlogloss:0.06744\n",
      "[43]\tvalidation-mlogloss:0.68971\ttrain-mlogloss:0.06427\n",
      "[44]\tvalidation-mlogloss:0.69598\ttrain-mlogloss:0.06161\n",
      "[45]\tvalidation-mlogloss:0.69745\ttrain-mlogloss:0.05843\n",
      "[46]\tvalidation-mlogloss:0.69882\ttrain-mlogloss:0.05749\n",
      "[47]\tvalidation-mlogloss:0.70152\ttrain-mlogloss:0.05555\n",
      "[48]\tvalidation-mlogloss:0.70889\ttrain-mlogloss:0.05414\n",
      "[49]\tvalidation-mlogloss:0.71358\ttrain-mlogloss:0.05272\n",
      "RMSE of the base model: 0.604\n",
      "Accuracy of the base model: 0.635\n",
      "Confusion matrix: \n",
      " [[60 25]\n",
      " [37 48]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "def xgboost_classifier(X_train, y_train, X_test, y_test, df_test):\n",
    "    dtrain_clf = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "    dtest_clf = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "    dpred_clf = xgb.DMatrix(df_test, enable_categorical=True)\n",
    "\n",
    "    params = {\"objective\": \"multi:softmax\",\"num_class\": 3, \"tree_method\": \"hist\",\n",
    "                \"learning_rate\": 0.3, \"max_depth\": 6,\n",
    "                \"gamma\": 0, \"subsample\": 1, \"colsample_bytree\": 1,\n",
    "                \"alpha\": 0, \"lambda\": 1,\"random_state\": 0}\n",
    "\n",
    "    n = 50\n",
    "    evals = [(dtest_clf, \"validation\"), (dtrain_clf, \"train\")]\n",
    "\n",
    "    model = xgb.train(\n",
    "       params=params,\n",
    "       dtrain=dtrain_clf,\n",
    "       num_boost_round=n,\n",
    "       evals=evals,\n",
    "       verbose_eval=1,\n",
    "       # Activate early stopping\n",
    "       early_stopping_rounds=30\n",
    "    )\n",
    "    preds = model.predict(dtest_clf)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    accuracy = accuracy_score(y_test, preds.round())\n",
    "\n",
    "    print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "    print(f\"Accuracy of the base model: {accuracy:.3f}\") \n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, preds)\n",
    "    print(\"Confusion matrix: \\n\", conf_matrix)\n",
    "    return preds\n",
    "\n",
    "xgb_pred = xgboost_classifier(X_train, y_train, X_test, y_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supposons que preds_dtree, preds_boost, preds_qda et preds_xgb sont vos prédictions\n",
    "df_preds = pd.DataFrame({\n",
    "    'RF': rf_pred,\n",
    "    'logreg': logpred,\n",
    "    'discri': discri_pred,\n",
    "    'dtree': decision_pred,\n",
    "    'boost': gradient_pred,\n",
    "    'qda': quadratic_pred,\n",
    "    'xgb': xgb_pred\n",
    "}, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "import time\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "# MLA = [\n",
    "#         #Ensemble Methods\n",
    "#         ensemble.AdaBoostClassifier(),\n",
    "#         ensemble.BaggingClassifier(),\n",
    "#         ensemble.ExtraTreesClassifier(),\n",
    "#         ensemble.GradientBoostingClassifier(),\n",
    "#         ensemble.RandomForestClassifier(),\n",
    "\n",
    "#         #Gaussian Processes\n",
    "#         gaussian_process.GaussianProcessClassifier(),\n",
    "        \n",
    "#         #GLM\n",
    "#         linear_model.LogisticRegressionCV(),\n",
    "#         linear_model.PassiveAggressiveClassifier(),\n",
    "#         linear_model.RidgeClassifierCV(),\n",
    "#         linear_model.SGDClassifier(),\n",
    "#         linear_model.Perceptron(),\n",
    "        \n",
    "#         #Navies Bayes\n",
    "#         naive_bayes.BernoulliNB(),\n",
    "#         naive_bayes.GaussianNB(),\n",
    "        \n",
    "#         #Nearest Neighbor\n",
    "#         neighbors.KNeighborsClassifier(),\n",
    "        \n",
    "#         #SVM\n",
    "#         svm.SVC(probability=True),\n",
    "        \n",
    "#         #Trees    \n",
    "#         tree.DecisionTreeClassifier(),\n",
    "#         tree.ExtraTreeClassifier(),\n",
    "        \n",
    "#         #Discriminant Analysis\n",
    "#         discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "#         discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "#         #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "#         XGBClassifier()    \n",
    "#         ]\n",
    "\n",
    "\n",
    "\n",
    "# #split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "# #note: this is an alternative to train_test_split\n",
    "# #cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "# #create table to compare MLA metrics\n",
    "# MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean','MLA Time','MLA RMSE']\n",
    "# MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# #create table to compare MLA predictions\n",
    "# MLA_predict = y_train.copy()\n",
    "\n",
    "# #index through MLA and save performance to table\n",
    "# row_index = 0\n",
    "# for alg in MLA:\n",
    "\n",
    "#     #set name and parameters\n",
    "#     MLA_name = alg.__class__.__name__\n",
    "#     MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "#     MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "#     # #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "#     # cv_results = model_selection.cross_validate(alg, X_train, y_train, cv  = cv_split)\n",
    "\n",
    "#     # #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "#     # MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "#     #save MLA predictions - see section 6 for usag\n",
    "#     start_time = time.time()\n",
    "#     alg.fit(X_train, y_train)\n",
    "#     predictions = alg.predict(X_test)\n",
    "#     end_time = time.time()\n",
    "#     # Calculer le RMSE et l'ajouter à la table\n",
    "#     accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "#     # Save the metrics to the table\n",
    "#     MLA_compare.loc[row_index, 'MLA Time'] = end_time - start_time\n",
    "#     MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = accuracy\n",
    "#     MLA_compare.loc[row_index, 'MLA RMSE'] = rmse\n",
    "    \n",
    "    \n",
    "#     MLA_predict[MLA_name] = predictions\n",
    "    \n",
    "#     row_index+=1\n",
    "\n",
    "    \n",
    "# #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "# MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "# MLA_compare1 = MLA_compare.copy()\n",
    "# MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml_models(X_train, y_train, X_test, y_test,df):\n",
    "    from sklearn import ensemble, gaussian_process, linear_model, naive_bayes, neighbors, svm, tree, discriminant_analysis\n",
    "    from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "    from xgboost import XGBClassifier\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    seed = 42  # Vous pouvez choisir n'importe quel nombre pour la graine\n",
    "\n",
    "    MLA = [\n",
    "        ensemble.AdaBoostClassifier(random_state=seed),\n",
    "        ensemble.BaggingClassifier(random_state=seed),\n",
    "        ensemble.ExtraTreesClassifier(random_state=seed),\n",
    "        ensemble.GradientBoostingClassifier(random_state=seed),\n",
    "        ensemble.RandomForestClassifier(random_state=seed),\n",
    "        gaussian_process.GaussianProcessClassifier(random_state=seed),\n",
    "        linear_model.LogisticRegressionCV(random_state=seed),\n",
    "        linear_model.PassiveAggressiveClassifier(random_state=seed),\n",
    "        linear_model.RidgeClassifierCV(),  # Pas de random_state pour RidgeClassifierCV\n",
    "        linear_model.SGDClassifier(random_state=seed),\n",
    "        linear_model.Perceptron(random_state=seed),\n",
    "        naive_bayes.BernoulliNB(),\n",
    "        naive_bayes.GaussianNB(),\n",
    "        neighbors.KNeighborsClassifier(),\n",
    "        svm.SVC(probability=True, random_state=seed),\n",
    "        tree.DecisionTreeClassifier(random_state=seed),\n",
    "        tree.ExtraTreeClassifier(random_state=seed),\n",
    "        discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "        XGBClassifier(random_state=seed)    \n",
    "    ]\n",
    "\n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean','MLA Time','MLA RMSE']\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "    MLA_predict = y_train.copy()\n",
    "\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "        start_time = time.time()\n",
    "        alg.fit(X_train, y_train)\n",
    "        predictions = alg.predict(X_test)\n",
    "        alg.fit(df.drop('target', axis=1), df['target'])\n",
    "        last_date_prediction = alg.predict(df.drop('target', axis=1).iloc[-1:])\n",
    "        end_time = time.time()\n",
    "\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "        MLA_compare.loc[row_index, 'MLA Time'] = end_time - start_time\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = accuracy\n",
    "        MLA_compare.loc[row_index, 'MLA RMSE'] = rmse\n",
    "\n",
    "        MLA_predict[MLA_name] = last_date_prediction\n",
    "\n",
    "        row_index+=1\n",
    "\n",
    "    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "    return MLA_compare, MLA_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLA_compare, MLA_predict = run_ml_models(X_train, y_train, X_test, y_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 00:00:00 2022-08-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-02 00:00:00 2022-08-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-03 00:00:00 2022-08-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-04 00:00:00 2022-08-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-04 00:00:00 2022-08-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-08 00:00:00 2022-08-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-09 00:00:00 2022-08-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-10 00:00:00 2022-08-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-11 00:00:00 2022-08-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-11 00:00:00 2022-08-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-15 00:00:00 2022-08-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-16 00:00:00 2022-08-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-17 00:00:00 2022-08-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-18 00:00:00 2022-08-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-18 00:00:00 2022-08-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-22 00:00:00 2022-08-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-23 00:00:00 2022-08-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-24 00:00:00 2022-08-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-25 00:00:00 2022-08-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-25 00:00:00 2022-08-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-28 00:00:00 2022-08-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-28 00:00:00 2022-08-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-02-28 00:00:00 2022-08-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "2022-03-01 00:00:00 2022-09-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-02 00:00:00 2022-09-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-04 00:00:00 2022-09-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-07 00:00:00 2022-09-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-07 00:00:00 2022-09-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-08 00:00:00 2022-09-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-09 00:00:00 2022-09-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-11 00:00:00 2022-09-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-14 00:00:00 2022-09-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-14 00:00:00 2022-09-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-15 00:00:00 2022-09-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-16 00:00:00 2022-09-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-18 00:00:00 2022-09-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-21 00:00:00 2022-09-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-21 00:00:00 2022-09-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-22 00:00:00 2022-09-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-23 00:00:00 2022-09-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-25 00:00:00 2022-09-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-28 00:00:00 2022-09-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-28 00:00:00 2022-09-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-29 00:00:00 2022-09-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "2022-03-30 00:00:00 2022-09-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/VerTebr0/opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "         date prediction      RMSE  accuracy                 model\n",
      "0  2022-08-01        [1]  0.480384  0.769231         XGBClassifier\n",
      "1  2022-08-02        [0]  0.480384  0.769231         XGBClassifier\n",
      "2  2022-08-03        [1]  0.480384  0.769231         XGBClassifier\n",
      "3  2022-08-04        [1]  0.480384  0.769231         XGBClassifier\n",
      "4  2022-08-05        [0]  0.480384  0.769231         XGBClassifier\n",
      "5  2022-08-08        [0]  0.480384  0.769231         XGBClassifier\n",
      "6  2022-08-09        [1]  0.480384  0.769231         XGBClassifier\n",
      "7  2022-08-10        [0]  0.480384  0.769231         XGBClassifier\n",
      "8  2022-08-11        [1]  0.480384  0.769231         XGBClassifier\n",
      "9  2022-08-12        [0]  0.480384  0.769231         XGBClassifier\n",
      "10 2022-08-15        [1]  0.480384  0.769231         XGBClassifier\n",
      "11 2022-08-16        [0]  0.480384  0.769231         XGBClassifier\n",
      "12 2022-08-17        [1]  0.480384  0.769231         XGBClassifier\n",
      "13 2022-08-18        [0]  0.480384  0.769231         XGBClassifier\n",
      "14 2022-08-19        [1]  0.480384  0.769231         XGBClassifier\n",
      "15 2022-08-22        [1]  0.480384  0.769231         XGBClassifier\n",
      "16 2022-08-23        [0]  0.480384  0.769231         XGBClassifier\n",
      "17 2022-08-24        [1]  0.480384  0.769231         XGBClassifier\n",
      "18 2022-08-25        [0]  0.480384  0.769231         XGBClassifier\n",
      "19 2022-08-26        [1]  0.480384  0.769231         XGBClassifier\n",
      "20 2022-08-29        [0]  0.480384  0.769231         XGBClassifier\n",
      "21 2022-08-30        [1]  0.480384  0.769231         XGBClassifier\n",
      "22 2022-08-31        [1]  0.480384  0.769231         XGBClassifier\n",
      "23 2022-09-01        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "24 2022-09-02        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "25 2022-09-05        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "26 2022-09-06        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "27 2022-09-07        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "28 2022-09-08        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "29 2022-09-09        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "30 2022-09-12        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "31 2022-09-13        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "32 2022-09-14        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "33 2022-09-15        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "34 2022-09-16        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "35 2022-09-19        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "36 2022-09-20        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "37 2022-09-21        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "38 2022-09-22        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "39 2022-09-23        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "40 2022-09-26        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "41 2022-09-27        [1]  0.430331  0.814815  ExtraTreesClassifier\n",
      "42 2022-09-28        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "43 2022-09-29        [0]  0.430331  0.814815  ExtraTreesClassifier\n",
      "44 2022-09-30        [1]  0.430331  0.814815  ExtraTreesClassifier\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Supposons que df_full est votre DataFrame complet qui contient toutes les données\n",
    "\n",
    "# Fonction pour créer un DataFrame pour une période donnée\n",
    "def create_df(start_date, end_date):\n",
    "    # Pour cet exemple, nous allons simplement filtrer df_full pour obtenir les données dans la période spécifiée.\n",
    "    df = df_btc[(df_btc['date'] >= start_date) & (df_btc['date'] <= end_date)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def predict_next_day(X_train, y_train, X_test, y_test, df, current_month, previous_month, best_model):\n",
    "    # Si nous sommes dans un nouveau mois ou si aucun meilleur modèle n'a encore été trouvé\n",
    "    if best_model_name is None or previous_month != current_month:\n",
    "        MLA_compare, MLA_predict = run_ml_models(X_train, y_train, X_test, y_test, df)\n",
    "        \n",
    "        # Calculer le ratio Accuracy/RMSE pour chaque modèle\n",
    "        MLA_compare['Accuracy/RMSE'] = MLA_compare['MLA Test Accuracy Mean'] / MLA_compare['MLA RMSE']\n",
    "        \n",
    "        # Trouver le modèle avec le meilleur ratio Accuracy/RMSE\n",
    "        MLA_compare['Accuracy/RMSE'] = pd.to_numeric(MLA_compare['Accuracy/RMSE'], errors='coerce')\n",
    "        best_model = MLA_compare.loc[MLA_compare['Accuracy/RMSE'].idxmax()]\n",
    "        print(best_model['MLA Name'])\n",
    "        previous_month = current_month\n",
    "    else :\n",
    "        previous_month = current_month\n",
    "        MLA_compare, MLA_predict = run_ml_models(X_train, y_train, X_test, y_test, df)\n",
    "        best_model = best_model\n",
    "        print(best_model['MLA Name'])\n",
    "        previous_month = current_month\n",
    "\n",
    "    \n",
    "    \n",
    "    return MLA_predict[best_model['MLA Name']], best_model['MLA Name'], best_model['MLA Test Accuracy Mean'], best_model['MLA RMSE'], previous_month, best_model\n",
    "\n",
    "\n",
    "# Initialiser la date de début et la date de fin\n",
    "prediction_start_date = datetime(2022, 8, 1)\n",
    "#end_date = df_btc['date'].max()\n",
    "end_date = datetime(2022,10,1)\n",
    "\n",
    "\n",
    "#isole un df qui contient les données entre les deux dates \n",
    "df = create_df(prediction_start_date, end_date)\n",
    "\n",
    "#récupère toute la colonne date afin de boucler dessus donc dans un nouveau df \n",
    "df_date = df['date']\n",
    "\n",
    "#mets df_date dans un dataframe\n",
    "df_date = pd.DataFrame(df_date)\n",
    "\n",
    "# Initialiser une liste vide pour stocker les dates de début\n",
    "start_dates = []\n",
    "\n",
    "# Parcourir chaque date dans df_date\n",
    "for date in df_date['date']:\n",
    "    # Calculer la date de début comme étant six mois avant la date actuelle\n",
    "    start_date = date - pd.DateOffset(months=6)\n",
    "    \n",
    "    # Vérifier si start_date est dans df_btc['date']\n",
    "    if start_date not in df_btc['date'].values:\n",
    "        # Si start_date n'est pas dans df_btc['date'], trouver la date la plus proche qui est dans df_btc['date']\n",
    "        start_date = df_btc['date'][df_btc['date'].sub(start_date).abs().idxmin()]\n",
    "    \n",
    "    # Ajouter la date de début à la liste start_dates\n",
    "    start_dates.append(start_date)\n",
    "\n",
    "# Ajouter la liste start_dates comme une nouvelle colonne 'start_date' dans df\n",
    "df_date['start_date'] = start_dates\n",
    "# Initialiser le DataFrame pour stocker les prédictions\n",
    "predictions_df = pd.DataFrame(columns=['date', 'prediction'])\n",
    "\n",
    "# Initialiser le meilleur modèle\n",
    "best_model_name = None\n",
    "best_model_accuracy = None\n",
    "best_model_rmse = None\n",
    "current_month = None\n",
    "previous_month = None\n",
    "best_model = None\n",
    "\n",
    "# Boucle sur chaque ligne dans df_Date\n",
    "for index, row in df_date.iterrows():\n",
    "    # Utiliser la valeur de la colonne 'date' comme current_date\n",
    "    current_date = row['date']\n",
    "    # Utiliser la valeur de la colonne 'start_date' comme window_start_date\n",
    "    window_start_date = row['start_date']\n",
    "\n",
    "    # Créer le DataFrame pour la période de la fenêtre glissante\n",
    "    df = create_df(window_start_date, current_date)\n",
    "    print(df['date'].min(), df['date'].max())\n",
    "\n",
    "    # Supposons que df est votre DataFrame\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(len(df) * train_ratio)\n",
    "\n",
    "    df_train = df.iloc[:train_size]\n",
    "    df_test = df.iloc[train_size:]\n",
    "\n",
    "    df_train = df_train.set_index('date')\n",
    "    df_test = df_test.set_index('date')\n",
    "\n",
    "    X_train = df_train.drop('target',axis=1)\n",
    "    y_train = df_train['target']\n",
    "    X_test = df_test.drop('target',axis=1)\n",
    "    y_test = df_test['target']\n",
    "\n",
    "    current_month = df['month'].iloc[-1]\n",
    "\n",
    "    #drop la colonne date\n",
    "    df = df.drop('date', axis=1)\n",
    "    \n",
    "    # Prédire la valeur pour le jour suivant\n",
    "    next_day_prediction, best_model_name, best_model_accuracy, best_model_rmse, previous_month, best_model = predict_next_day(X_train, y_train, X_test, y_test, df, current_month, previous_month, best_model)\n",
    "    \n",
    "    # Ajouter la prédiction, le nom du modèle, l'accuracy et le RMSE au DataFrame des prédictions\n",
    "    predictions_df = predictions_df.append({\n",
    "        'date': current_date, \n",
    "        'prediction': next_day_prediction,\n",
    "        'model': best_model_name,\n",
    "        'accuracy': best_model_accuracy,\n",
    "        'RMSE': best_model_rmse\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de prédictions correctes : 45\n"
     ]
    }
   ],
   "source": [
    "# Fusionner predictions_df et df_btc sur la colonne 'date'\n",
    "df_merged = pd.merge(predictions_df, df_btc[['date', 'target']], on='date')\n",
    "\n",
    "# Comparer les colonnes 'prediction' et 'target'\n",
    "df_merged['correct'] = df_merged['prediction'] == df_merged['target']\n",
    "\n",
    "# Compter le nombre de prédictions correctes\n",
    "num_correct_predictions = df_merged['correct'].sum()\n",
    "\n",
    "print(f\"Nombre de prédictions correctes : {num_correct_predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
